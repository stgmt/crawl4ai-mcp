version: '3.8'

services:
  # Crawl4AI MCP Server
  crawl4ai-mcp:
    build: .
    image: stgmt/crawl4ai-mcp:latest
    container_name: crawl4ai-mcp
    restart: unless-stopped
    ports:
      - "3000:3000"  # HTTP transport
      - "3001:3001"  # SSE transport
    environment:
      - CRAWL4AI_ENDPOINT=${CRAWL4AI_ENDPOINT:-http://crawl4ai:8000}
      - HTTP_PORT=${HTTP_PORT:-3000}
      - SSE_PORT=${SSE_PORT:-3001}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - DEBUG=${DEBUG:-false}
      - MAX_CONCURRENT_REQUESTS=${MAX_CONCURRENT_REQUESTS:-10}
      - REQUEST_TIMEOUT=${REQUEST_TIMEOUT:-30}
    networks:
      - crawl4ai-network
    depends_on:
      - crawl4ai
    healthcheck:
      test: ["CMD", "python", "-c", "import httpx; httpx.get('http://localhost:3000/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Crawl4AI Backend Service
  crawl4ai:
    image: unclecode/crawl4ai:latest
    container_name: crawl4ai
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      - PORT=8000
      - WORKERS=4
      - LOG_LEVEL=INFO
    networks:
      - crawl4ai-network
    volumes:
      - crawl4ai-data:/app/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

networks:
  crawl4ai-network:
    driver: bridge

volumes:
  crawl4ai-data:
    driver: local